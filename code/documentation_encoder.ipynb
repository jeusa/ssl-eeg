{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "427addc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import os\n",
    "\n",
    "from ssl_eeg import preprocessing as pr, preprocessing_nback as prn, preprocessing_unlabeled as pru, model, prediction as prd, metrics, plot\n",
    "\n",
    "models_doc_path = model.models_doc_path\n",
    "models_conf_path = model.models_conf_path\n",
    "models_doc = pd.read_csv(models_doc_path, index_col=0)\n",
    "models_conf = pd.read_csv(models_conf_path, index_col=0)\n",
    "\n",
    "root_dir = os.getcwd().split(\"code\")[0]\n",
    "accuracies_path = os.path.join(root_dir, \"models\", \"accuracies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994044f6",
   "metadata": {},
   "source": [
    "### Metric calculation for encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b004d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate validation and test accuracy for n-back using knn\n",
    "d_type = \"euclidean\"\n",
    "pool_labels = True\n",
    "\n",
    "for i, row in models_doc.iterrows():\n",
    "    cur_conf = models_conf.loc[row[\"conf_id\"]]\n",
    "    \n",
    "    print(row[\"model_name\"])\n",
    "    test_model = model.load_model(row[\"model_name\"]+\"_best_val\", cur_conf[\"out_dim\"], dropout_p=cur_conf[\"dropout_p\"])\n",
    "\n",
    "    # n-back data\n",
    "    blocks, chunks = prn.arange_data(lowpass=cur_conf[\"filter\"], trans_band_auto=False, verbose=False)\n",
    "    train_chunks, test_chunks = prn.get_train_test_sets(chunks, cur_conf[\"test_session\"])\n",
    "    \n",
    "    pool_txt = \"\"\n",
    "    if pool_labels:\n",
    "        pool_txt = \"pool_\"\n",
    "\n",
    "    if cur_conf[\"supervised\"] == \"supervised\":\n",
    "        # validation\n",
    "        folds = pr.get_folds(train_chunks, k_folds=10)\n",
    "        train_set, val_set = pr.get_train_val_sets(folds, row[\"val_idx\"])\n",
    "        pred_out, acc = prd.make_predictions(val_set, train_set, test_model, k=7, blocks=blocks, distance_type=d_type, pool_labels=pool_labels)\n",
    "        mae = metrics.calc_mae(pred_out)\n",
    "\n",
    "        models_doc.loc[i, \"val_\" + pool_txt + \"mae\"] = mae\n",
    "        models_doc.loc[i, \"val_\" + pool_txt + \"acc\"] = acc\n",
    "        print(acc, mae)\n",
    "\n",
    "        # test\n",
    "        pred_out, acc = prd.make_predictions(test_chunks, train_chunks, test_model, k=7, blocks=blocks, distance_type=d_type, pool_labels=pool_labels)\n",
    "        mae = metrics.calc_mae(pred_out)\n",
    "\n",
    "        models_doc.loc[i, \"test_\" + pool_txt + \"mae\"] = mae\n",
    "        models_doc.loc[i, \"test_\" + pool_txt + \"acc\"] = acc\n",
    "        print(acc, mae)\n",
    "    \n",
    "    elif cur_conf[\"supervised\"] == \"self-supervised\":           \n",
    "        # test using disjoint sessions\n",
    "        acc_mean = 0\n",
    "        mae_mean = 0\n",
    "\n",
    "        for t_s in range(4):\n",
    "            train_chunks, test_chunks = prn.get_train_test_sets(chunks, test_session=t_s+1)\n",
    "            pred_out, acc = prd.make_predictions(test_chunks, train_chunks, test_model, k=7, blocks=blocks, \n",
    "            distance_type=\"euclidean\", pool_labels=pool_labels)\n",
    "            acc_mean += acc\n",
    "            mae_mean += metrics.calc_mae(pred_out)\n",
    "\n",
    "        acc_mean = acc_mean / 4\n",
    "        mae_mean = mae_mean / 4\n",
    "        models_doc.loc[i, \"test_\" + pool_txt + \"mae\"] = mae_mean\n",
    "        models_doc.loc[i, \"test_\" + pool_txt + \"acc\"] = acc_mean\n",
    "        print(acc_mean)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf87d333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean values for validation loss and accuracy\n",
    "for c_id, frame in models_doc.groupby(\"conf_id\"):\n",
    "    m = frame[[\"val_loss\", \"train_loss\"]].mean(axis=0)\n",
    "    v = frame[[\"val_loss\", \"train_loss\"]].std(axis=0)\n",
    "    models_conf.loc[c_id, [\"mean_val_loss\", \"mean_train_loss\", \"std_val_loss\", \"std_train_loss\"]] = [m[\"val_loss\"], m[\"train_loss\"], v[\"val_loss\"], v[\"train_loss\"]]\n",
    "    \n",
    "    mtr = [\"acc\", \"mae\"]\n",
    "    for me in mtr:\n",
    "        if not ((pool_txt == \"pool_\") and (me == \"mae\")):\n",
    "            m_a = frame[\"val_\" + pool_txt + me].mean(axis=0)\n",
    "            v_a = frame[\"val_\" + pool_txt + me].std(axis=0)\n",
    "            models_conf.loc[c_id, [\"mean_val_\" + pool_txt + me, \"std_val_\" + pool_txt + me]] = [m_a, v_a]\n",
    "            \n",
    "            m_t = frame[\"test_\" + pool_txt + me].mean(axis=0)\n",
    "            v_t = frame[\"test_\" + pool_txt + me].std(axis=0)\n",
    "            models_conf.loc[c_id, [\"mean_test_\" + pool_txt + me, \"std_test_\" + pool_txt + me]] = [m_t, v_t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44a5381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate triplet validation accuracy for self-supervised models\n",
    "for i, row in models_doc.iterrows():\n",
    "    cur_conf = models_conf.loc[row[\"conf_id\"]]\n",
    "    \n",
    "    if (cur_conf[\"supervised\"] == \"self-supervised\"):\n",
    "        print(row[\"model_name\"])\n",
    "        test_model = model.load_model(row[\"model_name\"]+\"_best_val\", cur_conf[\"out_dim\"], dropout_p=cur_conf[\"dropout_p\"])\n",
    "\n",
    "        # unlabeled data\n",
    "        blocks_u, chunks_u = pru.arange_data(lowpass=cur_conf[\"filter\"], trans_band_auto=False, verbose=False)\n",
    "        blocks_ut = torch.from_numpy(blocks_u.to_numpy()).T\n",
    "\n",
    "        # for disjoint training and validation sets\n",
    "        val_ses = row[\"val_idx\"]\n",
    "        tr_chunks = chunks_u.loc[chunks_u[\"session_no\"] != val_ses]\n",
    "        val_chunks = chunks_u.loc[chunks_u[\"session_no\"] == val_ses]\n",
    "        tr_chunks = torch.from_numpy(tr_chunks.to_numpy())\n",
    "        val_chunks = torch.from_numpy(val_chunks.to_numpy())\n",
    "\n",
    "        val_acc = metrics.calc_triplet_accuracies_ssl(test_model, val_chunks, blocks_ut, augmentation_scale=cur_conf[\"augmentation_scale\"], loss_margin=0, file_name=row[\"model_name\"])\n",
    "        print(val_acc)\n",
    "        models_doc.loc[i, \"triplet_val_acc\"] = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bbb00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate triplet test accuracy for self-supervised models on n-back data\n",
    "\n",
    "for i, row in models_doc.iterrows():\n",
    "    cur_conf = models_conf.loc[row[\"conf_id\"]]\n",
    "    \n",
    "    if (cur_conf[\"supervised\"] == \"self-supervised\"):\n",
    "        print(row[\"model_name\"])\n",
    "        test_model = model.load_model(row[\"model_name\"]+\"_best_val\", cur_conf[\"out_dim\"], dropout_p=cur_conf[\"dropout_p\"])\n",
    "\n",
    "        # n-back data\n",
    "        blocks, chunks = prn.arange_data(lowpass=cur_conf[\"filter\"], trans_band_auto=False, verbose=False)\n",
    "        blocks_t = torch.from_numpy(blocks.drop(columns=[\"time_stamp\", \"n\"]).to_numpy()).T\n",
    "\n",
    "        chunks_t = torch.from_numpy(chunks.drop(columns=[\"n\", \"offset\"]).to_numpy())\n",
    "        \n",
    "        acc = metrics.calc_triplet_accuracies_ssl(test_model, chunks_t, blocks_t, augmentation_scale=cur_conf[\"augmentation_scale\"], loss_margin=0, file_name=row[\"model_name\"] + \"_nback\")\n",
    "        print(acc)\n",
    "        models_doc.loc[i, \"triplet_test_acc\"] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01c74af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate triplet validation and test accuracy for supervised models on n-back data\n",
    "calc_val_acc = True\n",
    "calc_test_acc = True\n",
    "\n",
    "for i, row in models_doc.iterrows():\n",
    "    cur_conf = models_conf.loc[row[\"conf_id\"]]\n",
    "    \n",
    "    if (cur_conf[\"supervised\"] == \"supervised\"):\n",
    "        print(row[\"model_name\"])\n",
    "        test_model = model.load_model(row[\"model_name\"]+\"_best_val\", cur_conf[\"out_dim\"], dropout_p=cur_conf[\"dropout_p\"])\n",
    "\n",
    "        # n-back data\n",
    "        blocks, chunks = prn.arange_data(lowpass=cur_conf[\"filter\"], trans_band_auto=False, verbose=False)\n",
    "        train_chunks, test_chunks = prn.get_train_test_sets(chunks, cur_conf[\"test_session\"])\n",
    "\n",
    "        # validation\n",
    "        if calc_val_acc:\n",
    "            chunks_data_X, chunks_data_Y = prn.get_samples_data(train_chunks, blocks)\n",
    "            chunks_data_X = pr.normalize_data(chunks_data_X)\n",
    "            folds = pr.get_folds(train_chunks, k_folds=10)\n",
    "            \n",
    "            train_set, val_set = pr.get_train_val_sets(folds, row[\"val_idx\"])\n",
    "            val_triplets = prn.make_triplets(val_set)\n",
    "            train_triplets = prn.make_triplets(train_set)\n",
    "            \n",
    "            val_acc = metrics.calc_triplet_accuracies_sl(test_model, val_triplets, chunks_data_X, loss_margin=0, file_name=row[\"model_name\"] + \"_nback\")\n",
    "        \n",
    "            print(val_acc)\n",
    "            models_doc.loc[i, \"triplet_val_acc\"] = val_acc\n",
    "\n",
    "        # test\n",
    "        if calc_test_acc:\n",
    "            test_chunks_data_X, test_chunks_data_Y = prn.get_samples_data(test_chunks, blocks)\n",
    "            test_chunks_data_X = pr.normalize_data(test_chunks_data_X)\n",
    "            test_triplets = prn.make_triplets(test_chunks)\n",
    "\n",
    "            test_acc = metrics.calc_triplet_accuracies_sl(test_model, test_triplets, test_chunks_data_X, loss_margin=0, file_name=row[\"model_name\"] + \"_nback_test\")\n",
    "\n",
    "            print(test_acc)\n",
    "            models_doc.loc[i, \"triplet_test_acc\"] = test_acc\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e5c5aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean values for triplet accuracy\n",
    "for c_id, frame in models_doc.groupby(\"conf_id\"):\n",
    "    m = frame[[\"triplet_val_acc\"]].mean(axis=0)\n",
    "    v = frame[[\"triplet_val_acc\"]].std(axis=0)\n",
    "    models_conf.loc[c_id, [\"mean_triplet_val_acc\", \"std_triplet_val_acc\"]] = [m[\"triplet_val_acc\"], v[\"triplet_val_acc\"]]\n",
    "\n",
    "    m = frame[[\"triplet_test_acc\"]].mean(axis=0)\n",
    "    v = frame[[\"triplet_test_acc\"]].std(axis=0)\n",
    "    models_conf.loc[c_id, [\"mean_triplet_test_acc\", \"std_triplet_test_acc\"]] = [m[\"triplet_test_acc\"], v[\"triplet_test_acc\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5064a543",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_conf.to_csv(model.models_conf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad5d7be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_doc.to_csv(model.models_doc_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
